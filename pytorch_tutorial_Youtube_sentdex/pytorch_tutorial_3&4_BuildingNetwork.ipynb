{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()    # dont forget this\n",
    "        self.fc1 = nn.Linear(28*28, 64)    #(input, output) of this fully connected layer\n",
    "        self.fc2 = nn.Linear(64, 64)       # input of this layer is the output of last layer\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)       # output 10: 10 labels\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))    # pass data x thourgh all layers with ReLu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1994, -2.3821, -2.3116, -2.3516, -2.3848, -2.2500, -2.3589, -2.1935,\n",
       "         -2.3345, -2.2825]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random data and pass it through our neural network\n",
    "X = torch.rand((28,28))\n",
    "\n",
    "# flatten the image, para:-1 means, you know how many column you need \n",
    "# but dont know how many rows you need, just let torch compute it for you\n",
    "X = X.view(-1, 28*28)\n",
    "\n",
    "# pass data into network and get output\n",
    "output = net(X)\n",
    "output    #output: prediction on classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0466, grad_fn=<NllLossBackward>)\n",
      "tensor(3.1352e-06, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(2.9966e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4495, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets \n",
    "\n",
    "train = datasets.MNIST(\"\", train = True, download = True, transform = transforms.Compose([transforms.Compose([transforms.ToTensor()])]))\n",
    "test = datasets.MNIST(\"\", train = False, download = True, transform = transforms.Compose([transforms.Compose([transforms.ToTensor()])])) \n",
    "trainset =  torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True )\n",
    "\n",
    "# optimizer: adjust parameters at every step\n",
    "# net.parameters(), adjustable paramters in the network\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "# epoch is the number of passes through the entire training set\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        #data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()    # clears old gradients from the last step\n",
    "        output = net(X.view(-1, 28*28))    #pass the data into network\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()    # computes the derivative of the loss w.r.t. the parameters (or anything requiring gradients) using backpropagation.\n",
    "        optimizer.step()   #  causes the optimizer to take a step based on the gradients of the parameters.\n",
    "    print(loss)    #print the loss of each epoch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.987\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# we dont want to calculate gradient here\n",
    "with torch.no_grad():\n",
    "        for data in trainset:\n",
    "            X, y = data\n",
    "            output = net(X.view(-1, 28*28))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[1].view(28,28))    # show one of the images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# see if the prediction is right for the image above\n",
    "print(torch.argmax(net(X[1].view(-1,28*28))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
